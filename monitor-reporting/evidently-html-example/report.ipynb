{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evidently Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'evidently'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18064\\1850700949.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mevidently\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mReport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mColumnMapping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mevidently\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mColumnDriftMetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDatasetDriftMetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDatasetMissingValuesMetric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'evidently'"
     ]
    }
   ],
   "source": [
    "from evidently import Report, ColumnMapping\n",
    "from evidently.metrics import ColumnDriftMetric, DatasetDriftMetric, DatasetMissingValuesMetric\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from mlflow import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_latest_version(model_name):\n",
    "    response = requests.post(\n",
    "        'http://experiment-tracking:5000/api/2.0/mlflow/registered-models/get-latest-versions',\n",
    "        json={\n",
    "            'name': model_name,\n",
    "            'stages': [\"None\"]\n",
    "        }\n",
    "    )\n",
    "    latest_versions = response.json().get('model_versions', [])\n",
    "    latest_version = latest_versions[-1]['version']\n",
    "    return latest_version\n",
    "\n",
    "def get_dataframe(run_id, month):\n",
    "    # Pas het pad aan naar jouw batch output (CSV-bestanden)\n",
    "    path = f\"batch-data/report/students/{run_id}_{month}.csv\"\n",
    "    return pd.read_csv(path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://experiment-tracking:5000\")\n",
    "client = MlflowClient(\"http://experiment-tracking:5000\")\n",
    "model_name = \"rf-math-pass-predictor\"\n",
    "latest_version = get_latest_version(model_name)\n",
    "model_latest = mlflow.pyfunc.load_model(f\"models:/{model_name}/{latest_version}\")\n",
    "\n",
    "# Stel dat je batch pipeline rapporten maakt voor verschillende maanden\n",
    "# Gebruik het juiste run_id van het model (of haal uit een batch-bestand)\n",
    "run_id = model_latest.metadata.run_id\n",
    "\n",
    "# Laad batch prediction resultaten voor verschillende maanden\n",
    "df_april = get_dataframe(run_id, \"april\")\n",
    "df_june  = get_dataframe(run_id, \"june\")\n",
    "\n",
    "# Pas de features aan naar jouw dataset\n",
    "num_features = []  # Bijvoorbeeld: []\n",
    "cat_features = [\"gender\", \"race/ethnicity\", \"parental level of education\", \"lunch\", \"test preparation course\"]\n",
    "\n",
    "column_mapping = ColumnMapping(\n",
    "    target=\"pass_math\",\n",
    "    prediction=\"pass_math_pred\",\n",
    "    numerical_features=num_features,\n",
    "    categorical_features=cat_features\n",
    ")\n",
    "\n",
    "report = Report(\n",
    "    metrics=[\n",
    "        ColumnDriftMetric(column_name='pass_math_pred'),\n",
    "        DatasetDriftMetric(),\n",
    "        DatasetMissingValuesMetric()\n",
    "    ]\n",
    ")\n",
    "\n",
    "report.run(reference_data=df_april, current_data=df_june, column_mapping=column_mapping)\n",
    "report.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
